{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "from WideResNet_pytorch.wideresnet import WideResNet\n",
    "\n",
    "from augmentations import *\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "CK_PATH = \"./ckpt/\"\n",
    "RES_PATH = \"./res/\"\n",
    "CORRUPTIONS = [\n",
    "    'clear',\n",
    "    'gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur',\n",
    "    'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog',\n",
    "    'brightness', 'contrast', 'elastic_transform', 'pixelate',\n",
    "    'jpeg_compression'\n",
    "]\n",
    "\n",
    "_CIFAR_MEAN, _CIFAR_STD = (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "def top_n_count(pred, target, n=5, normalized=True):\n",
    "    questions, options = pred.shape\n",
    "    choices = np.argsort(-pred, axis=1)\n",
    "    cnt = 0\n",
    "    for i in range(questions):\n",
    "        if target[i] in choices[i,0:n]:\n",
    "            cnt += 1\n",
    "    if normalized:\n",
    "        return cnt / questions\n",
    "    else:\n",
    "        return cnt\n",
    "\n",
    "def JSLoss(p1, p2, p3):\n",
    "    kldiv = nn.KLDivLoss(reduction='batchmean')\n",
    "    m = (p1 + p2 + p3) / 3\n",
    "    log_m = m.log()\n",
    "    res = (kldiv(log_m, p1) + kldiv(log_m, p2) + kldiv(log_m, p3)) / 3\n",
    "    return res\n",
    "\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    def update(self, val, weight=1):\n",
    "        self.val = val\n",
    "        self.sum += val * weight\n",
    "        self.count += weight\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "class AugMix:\n",
    "    def __init__(self, k=3, alpha = 1, js_on=True, output_size=(3, 32, 32), pre_aug=transforms.RandomCrop(32), pre_process=transforms.ToTensor()):\n",
    "        self.k = 3\n",
    "        self.alpha = 1\n",
    "        self.js_on = js_on\n",
    "        self.augmentations = augmentations\n",
    "        self.output_size = output_size\n",
    "        self.pre_aug=pre_aug\n",
    "        self.pre_process=pre_process\n",
    "        self.draw_dirichlet = lambda : np.random.dirichlet(tuple(self.alpha for _ in range(self.k)))\n",
    "        self.draw_beta = lambda : np.random.beta(self.alpha, self.alpha)\n",
    "        self.draw_chainlength = lambda : np.random.randint(1,3)\n",
    "        self.draw_operation = lambda : np.random.choice(self.augmentations, 3)\n",
    "        \n",
    "    def __call__(self, pil_img):\n",
    "        ori = self.pre_aug(pil_img)\n",
    "        processed_ori = self.pre_process(ori)\n",
    "        cnt = 2 if self.js_on else 1\n",
    "        results = []\n",
    "        for _ in range(cnt):\n",
    "            res = torch.zeros(self.output_size)\n",
    "            w = self.draw_dirichlet()\n",
    "            for i in range(self.k):\n",
    "                ops = self.draw_operation()\n",
    "                chainlength = self.draw_chainlength()\n",
    "                ops = ops[0:chainlength]\n",
    "                src = ori\n",
    "                for op in ops:\n",
    "                    src = op(src)\n",
    "                src = self.pre_process(src)\n",
    "                res += w[i] * src\n",
    "            m = self.draw_beta()\n",
    "            res = m * processed_ori + (1 - m) * res\n",
    "            results.append(res)\n",
    "        if self.js_on:\n",
    "            results.append(processed_ori)\n",
    "        return torch.stack(results).squeeze(dim=0)\n",
    "\n",
    "def main(augmix_on=True, js_on=True, train_on=True, eval_on=True, use_cifar10=False):\n",
    "    TAG = (\"AugMix\" if augmix_on else \"Standard\") + (\"_JSLoss\" if augmix_on and js_on else \"\") \n",
    "    torch.manual_seed(2020)\n",
    "    np.random.seed(2020)\n",
    "    epochs = 100\n",
    "    batch_size = 256\n",
    "    if js_on:\n",
    "        LAMBDA = 12\n",
    "    if use_cifar10:\n",
    "        TESTSET = \"CIFAR-10\"\n",
    "    else:\n",
    "        TESTSET = \"CIFAR-100\"\n",
    "    print(\"[{}_{}] starts\".format(TAG, TESTSET))\n",
    "    # 1. dataload\n",
    "    # basic augmentation & preprocessing\n",
    "    train_base_aug = [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(32, padding=4)\n",
    "    ]\n",
    "    preprocess = [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(_CIFAR_MEAN, _CIFAR_STD)\n",
    "    ]\n",
    "    \n",
    "    # apply augmix at transformation stage\n",
    "    train_transform = AugMix(js_on=js_on, pre_aug=transforms.Compose(train_base_aug), \n",
    "                             pre_process=transforms.Compose(preprocess)) if augmix_on else transforms.Compose(train_base_aug + preprocess)\n",
    "    test_transform = transforms.Compose(preprocess)\n",
    "    \n",
    "    # load data\n",
    "    if use_cifar10:\n",
    "        train_data = datasets.CIFAR10('./data/cifar', train=True, transform=train_transform, download=True)\n",
    "        test_data = datasets.CIFAR10('./data/cifar', train=False, transform=test_transform, download=True)\n",
    "    else: \n",
    "        train_data = datasets.CIFAR100('./data/cifar', train=True, transform=train_transform, download=True)\n",
    "        test_data = datasets.CIFAR100('./data/cifar', train=False, transform=test_transform, download=True)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "                   train_data,\n",
    "                   batch_size=batch_size,\n",
    "                   shuffle=True,\n",
    "                   num_workers=4,\n",
    "                   pin_memory=True)\n",
    "                   \n",
    "    # 2. model\n",
    "    # wideresnet 40-2\n",
    "    model = WideResNet(depth=40, num_classes=100, widen_factor=2, drop_rate=0.0)\n",
    "\n",
    "    # 3. Optimizer & Scheduler\n",
    "    optimizer = torch.optim.SGD(\n",
    "                  model.parameters(),\n",
    "                  0.1,\n",
    "                  momentum=0.9,\n",
    "                  weight_decay=0.0005,\n",
    "                  nesterov=True)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs*len(train_loader), eta_min=1e-6, last_epoch=-1)\n",
    "\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "    # 4. training\n",
    "    if train_on:\n",
    "        model.train()\n",
    "        softmax_train = nn.Softmax(dim=1)\n",
    "        losses = []\n",
    "        duration = AverageMeter()\n",
    "        for epoch in range(epochs):\n",
    "            elapsed = time.time()\n",
    "            for i, (images, targets) in enumerate(train_loader):\n",
    "                images, targets = images.cuda(), targets.cuda()\n",
    "                optimizer.zero_grad()\n",
    "                if augmix_on and js_on:\n",
    "                    # Jensen-Shannon Divergence Loss\n",
    "                    d = images.shape\n",
    "                    assert(d[1]==3)\n",
    "                    images_flatten = images.view(3 * d[0], d[2], d[3], d[4])\n",
    "                    preds = softmax_train(model(images_flatten))\n",
    "                    p1 = preds[::3]\n",
    "                    p2 = preds[1::3]\n",
    "                    p_ori = preds[2::3]\n",
    "                    js = JSLoss(p1, p2, p_ori)\n",
    "                    loss = F.nll_loss(p_ori.log(), targets) + LAMBDA * js\n",
    "                else:\n",
    "                    logits = model(images)\n",
    "                    loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                losses.append(loss.item())\n",
    "                if i % 100 == 0 or i+1 == len(train_loader):\n",
    "                    print(\"Train Loss: {:.4f}\".format(loss.item()))\n",
    "                    if augmix_on and js_on:\n",
    "                        print(\"JSLoss: {:.4f}\".format(js))\n",
    "            \n",
    "            elapsed = time.time() - elapsed\n",
    "            duration.update(elapsed)\n",
    "            torch.save({\n",
    "                \"epoch\": epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'losses': losses\n",
    "            }, CK_PATH + TAG + \"/{}/epoch_{}.pt\".format(TESTSET, epoch + 1))\n",
    "        # report duration taken for an epoch\n",
    "        with open('{}_{}_duration.txt'.format(RES_PATH + TAG, TESTSET),'w') as f:\n",
    "            f.write(\"Last Value: {}\\nAverage: {}\".format(duration.val, duration.avg))\n",
    "            \n",
    "    # 4. evaluation\n",
    "    if eval_on:\n",
    "        chpk = torch.load(CK_PATH + TAG + \"/{}/epoch_100.pt\".format(TESTSET))\n",
    "        model.load_state_dict(chpk['model_state_dict'])\n",
    "        model.eval()\n",
    "        softmax_eval = nn.Softmax(dim=1)\n",
    "        errors = []\n",
    "        with torch.no_grad():\n",
    "            # evaluate on cirfar100, cifar100-c\n",
    "            for corruption in CORRUPTIONS:\n",
    "                print(\"CORRUPTIONS: {}\".format(corruption))\n",
    "                if corruption != 'clear':\n",
    "                    # use corrupted testset\n",
    "                    test_data.data = np.load('./data/cifar/{}-C/{}.npy'.format(TESTSET, corruption))\n",
    "                    test_data.targets = np.load('./data/cifar/{}-C/labels.npy'.format(TESTSET))\n",
    "                test_loader = torch.utils.data.DataLoader(\n",
    "                               test_data,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=False,\n",
    "                               num_workers=4,\n",
    "                               pin_memory=True)\n",
    "                corrects = 0\n",
    "                for _, (inputs, targets) in enumerate(test_loader):\n",
    "                    logits = model(inputs)\n",
    "                    preds =  softmax_eval(logits).detach().cpu().numpy()\n",
    "                    corrects += top_n_count(preds, targets.numpy(), n=1, normalized=False)\n",
    "                error = 1 - corrects / len(test_data)\n",
    "                print(\"[{}] \\\"{}-{}\\\" error rate: {:.6}\".format(TAG, TESTSET, corruption, error))\n",
    "                errors.append((corruption, error))\n",
    "            # report errors for each testset\n",
    "            np.savetxt('{}_{}.csv'.format(RES_PATH + TAG, TESTSET), np.array(errors), delimiter=',', fmt=\"%s\")\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # cifar-100\n",
    "    main(augmix_on=True, js_on=True)\n",
    "    main(augmix_on=True, js_on=False)\n",
    "    main(augmix_on=False, js_on=False)\n",
    "    # cifar-10\n",
    "    main(augmix_on=True, js_on=True, use_cifar10=True)\n",
    "    main(augmix_on=True, js_on=False, use_cifar10=True)\n",
    "    main(augmix_on=False, js_on=False, use_cifar10=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
